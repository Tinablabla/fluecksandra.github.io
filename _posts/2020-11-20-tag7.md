---
title: "Tag 7 : Metadaten modellieren und Schnittstellen nutzen 2/2"
date: 2020-11-20
---

Schlagwörter: OpenRefine, Datentransformation, CSV, MARCXML

In dieser Vorlesung befassten wir uns erneut mit dem Thema Metadaten modellieren und Schnittstellen nutzen. Heute ging es darum Metadaten mit der Software OpenRefine von CSV nach MARCXML zu transformieren.
Als Vorbereitung auf diese Lektion haben wir OpenRefine installiert und die [Lehrmaterialien von Library Carpentry zu OpenRefine](https://librarycarpentry.org/lc-open-refine/) durchgearbeitet. In dieser Vorlesung machten wir nun weitere Übungen mit den Beispieldaten, die wir bereits für den Vorbereitungsauftrag in OpenRefine geladen hatten (siehe *doaj-article-sample.csv* im Schaubild).

![]({{site.baseurl}}/images/schaubild_20201120.png)

# Einführung OpenRefine

Zunächst starteten wir mit einer Einführung in die Software OpenRefine. Der Claim der Software lautet wie folgt:

> “A free, open source, powerful tool for working with messy data”

Für OpenRefine gibt es viele verschiedene Einsatzbereiche. Die Software wird vorwiegend für die Bereinigung, Konvertierung, Anreicherung und Analyse von Daten verwendet. Sie wird lokal installiert und über den Browser bedient. OpenRefine ist keine bibliotheksspezifische Software, wird aber dennoch sehr oft im Bibliotheksbereich verwendet. Die Software ist besonders geeignet für tabellarische Daten (CSV, TSV, XLS, XLSX etc.). Auch einfaches XML (z.B MARCXML) oder JSON sei mit etwas Übung noch relativ einfach zu modellieren. 

Konkrete Einsatzmöglichkeiten von OpenRefine sind:
* Exploration von Datenlieferungen (z.B gelieferte Verlagsdaten prüfen)
* Vereinheitlichung und Bereinigung von Daten
* Abgleich mit Normdaten (nennt man auch "Reconciliation") aus der GND oder VIAF

Interessant ist, dass die Firma metaweb, welche die Software entwickelte, zunächst von Google gekauft -und dann schliesslich an die OpenSource-Community weitergegeben wurde.
Ganz zu Beginn hiess die Software Freebase Gridworks, anschliessend Google Refine und zum Schluss dann OpenRefine. Quelle: [OpenRefine (Wikipedia)](https://en.wikipedia.org/wiki/OpenRefine).

Exkurs ALMA: Es gibt ein ALMA Refine. Ex libris hat Funktionalitäten von der OS-Software übernommen. 

## Übung: CSV nach MARCXML mit OpenRefine
Für die Transformation nutzten wir die Funktion "Templating Exporter".

![]({{site.baseurl}}/images/openrefine_templating.png)

### Aufgabe 1: Reverse Engineering
Zunächst ging es darum die Ausgangsdaten mit dem Ergebnis zu Vergleichen und die Transformationen in den verschiedenen Feldern zu beschreiben. Dafür nutzten wir eine Vorlage der Dozierenden. Links wurd diese Vorlage eingegeben und rechts werden die Daten entsprechend ausgegeben.

![]({{site.baseurl}}/images/openrefine_csvnachmarcxml.png)

Folgende Erkenntnisse wurde aus dem Vergleich gezogen:
* leader: ist hart kodiert (wird rechts genau so übernommen wie links vorgegeben)
* 001: Der erste Teil der URL wird mit der einfachen replace-Funktion ersetzt durch " " (-> nichts) und somit nicht ausgegeben. Das ist praktisch, weil der erste Teil der URL sowieso überall gleich wäre.
* 022: Die ISSN wird ganz einfach ausgelesen
* 100: Nur der erste Autor wird ausgegeben (Feld 100 ist in MARC nur für die Haupteintragung vorgesehen). Die Autoren werden gesplittet über die Pipe. Nach dem Splitten sind alle Autoren in einer Array. Über die [0] wird das erste Element des Arrays angesteuert und ausgegeben.
* 245: Der Titel wird unverändert ausgegeben (durch den Befehl *.escape("xml")* wird dafür gesorgt, dass keine unerlaubte Zeichen im Titel sind)
* 700: Alle Autor'innen ausser der 1. Person werden durch die Schleifenfunktion *forEach* nacheinander ausgegeben. Zunächst werden die Autoren aufgesplittet und in ein Array gespeichert. Über den Befehl *slice* wird das vorderste Element (1) abgeschnitten. Die Autoren werden in der Variable v gespeichert und dann im Element 700, Unterfeld a ausgegeben.

### Aufgabe 2: Eigene Regeln erstellen
Nun sollten wir in Gruppen eine eigene geeignete Regel erstellen, um die gewünschten Daten der gewählten Spalten in MARC21 zu transformieren. Dafür mussten wir zunächst herausfinden, welche Spalte aus den DOAJ-Daten welchen Feldern und Unterfeldern in [MARC21](https://www.loc.gov/marc/bibliographic/) entsprechen. Wir haben uns für die Spalte "Publisher" entschieden. Die Daten aus dieser Spalte gaben wir mit folgender Regel in Feld 260, Unterfeld b aus.
```
<datafield tag="260" ind1=" " ind2=" ">
    <subfield code="b">{{cells["Publisher"].value.escape('xml')}}
</datafield>
```
**Problem mit leeren Zellen**

Es ist möglich, dass Zellen leere werten enthalten. Es sollten Regeln geschaffen werden, was passieren soll, wenn die Zelle leer ist. Es gibt 2 Arten von leeren Zellen. Es kann "gar nichts" drin sein (-> leerer String) oder es kann eine technische "null" sein.
Wenn die Spalten leere Zellen enthalten, dann sollte die Funktion `forNonBlank()` verwendet werden. Mit dieser Funktion kann dafür gesorgt werden, dass, je nach dem, ob Werte in der Zelle vorhanden sind oder eben nicht, bestimmte Daten ausgegeben werden sollen.

Beispiel:

```xml
{{
forNonBlank(
    cells['DOI'].value,
    v,
    '<datafield tag="024" ind1="7" ind2=" ">
        <subfield code="a">' + v.escape('xml') + '</subfield>
        <subfield code="2">doi</subfield>        
    </datafield>',
    ''
)
```
}}
```















