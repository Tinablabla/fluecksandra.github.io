---
title: "Tag 8 : Suchmaschinen und Discovery-Systeme 1/2"
date: 2020-11-27
---
 
Schlagwörter: Validierung, XML, Tools zur Datentransformation???????

## Nachtrag zu Metadaten modellieren und Schnittstellen nutzen
An diesem Tag diskutierten wir im Rahmen eines Nachtrages zum Thema "Metadaten modellieren und Schnittstellen nutzen" zunächst die Aufgabe zur Anreicherung mit lobid-gnd. Die Lösungen wurden im [Zusatzartikel zur Aufgabe Anreicherung mit lobid-gnd](https://fluecksandra.github.io/2020/11/23/extra.html) nachgetragen. Anschliessend widmeten wir uns der Validierung der XML-Datei.

### Validierung von XML
Das Ergebnis wurde als XML in ein neues Verzeichnis exportiert und anschliessend validiert. Bei der Validierung stellte sich heraus, dass die Subfields bei 260 und 264 im gemeinsamen Template falsch waren. Die schliessenden Tags fehlten und mussten noch ergänzt werden. Nach einer Korrektur im Template und einem erneuten Export wurde bei der Validierung zum Glück kein Fehler mehr ausgegeben.

**Exkurs: XML Deklaration**

XML-Dateien enthalten in der ersten Zeile eine "Deklaration". Damit wird den verarbeitenden Programmen mitgeteilt, dass es sich um eine XML-Datei handelt.
Die Angabe der Version ist Pflicht, der Rest muss nicht zwingend angegeben werden. Nachfolgend ein Paradebeispiel für eine XML-Deklaration:
 ```{% raw %}
  <?xml version="1.0" encoding="utf-8" standalone="yes"?>
{% endraw %}
```
Erkärung der XML-Deklaration:

Die Datei ist eine XML-Datei (?xml), sie entspricht dem XML-Standard in Version 1.0, die Zeichencodierung erfolgt im Standard "Unicode" (das heisst, dass Sonderzeichen wie Umlaute erlaubt sind) und schliesslich steht, dass die Datei eine Dokumenttypdefinition (DTD) enthält. DTDs gibt es oft keine. 


### Weitere Tools zur Metadatentransformation

**Motivation : wieso Metadaten transformieren?**

Siehe dazu das [Youtube-Video der Metadatenmanagerin Kristen Jeude](https://www.youtube.com/watch?v=YwbRTDvt_sA). Sie spricht die "Sprache der Daten" und sorgt dafür dass bibliografische Nachweise aus verschiedenen Datenbanken zusammengeführt werden können. Die bibliografischen Daten werden in den Datenbanken nach verschiedenen Standards gespeichert. Diese Standards müssen "übersetzt" werden um sie zusammenführen zu können.

Vorteil für Nutzende: Daten aus den verschiedensten Quellen können auf einer Suchoberfläche durchsucht werden.

**Andere Tools?**

Die Wahl der Software ist oftmals Abhängig von den Fähigkeiten der Mitarbeitenden. Es wird diejenige Software gewählt, die schon gut beherrscht wird, obwohl die Software im Idealfall anhand des jeweiligen Anwendungsfalls gewählt würde. Wer alle Tools beherrscht, ist also stark im Vorteil!
Open Refine ist gut für den "Start". Wer gerne und gut programmiert kann auch Software wie Catmandu (Perl) oder Metafacture (Java) verwenden. Für die Arbeit mit MARC21-Daten kann natürlich auch MarcEdit verwendet werden. 


### Nutzung von JSON-APIs

Oftmals werden bei modernen Schnittstellen Daten im JSON-Format ausgeliefert (Alternative: XML wie bei SRU oder OAI-MPH). JSON kann ebenfalls im Browser angeschaut werden. Ein Beispiel ist die [API der lobid-gnd](https://lobid.org/gnd/api). Mit dem Tool [scrAPIr](https://scrapir.org) könnten Daten über die APIs der Webseiten bezogen werden.
Beispiel Deutsches Literaturarchiv in Marbach.
Kann gut ausgewertet werden.


### Metadatenstandard LIDO



## Suchmaschinen und Discovery-Systeme

### Installation und Konfiguration von VuFind
### Funktion von Suchmaschinen am Beispiel von Solr
